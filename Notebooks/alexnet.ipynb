{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okon/anaconda2/envs/newtf/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import math, os, json, sys, re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice\n",
    "from numpy import newaxis\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "\n",
    "from alexnet import AlexNet_base\n",
    "import theano\n",
    "\n",
    "keras.backend.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras.backend.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/triplet-loss-with-svc/alexnet/train/'\n",
    "test_dir = '/triplet-loss-with-svc//alexnet/test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for generating batches\n",
    "def get_batches(dirname, gen=image.ImageDataGenerator(data_format='channels_first'), shuffle=False, batch_size=32, class_mode='categorical',\n",
    "                target_size=(227,227)):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "# Function for getting classes\n",
    "def get_classes():\n",
    "    batches = get_batches(train_dir, shuffle=False, batch_size=1)\n",
    "    test_batches = get_batches(test_dir, shuffle=False, batch_size=1)\n",
    "    return (batches.classes,onehot(batches.classes),batches.filenames, test_batches.filenames)\n",
    "\n",
    "# Load all data\n",
    "def get_data(path, target_size=(227,227)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.samples)])\n",
    "\n",
    "def onehot(x):\n",
    "    return to_categorical(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n",
      "Found 22424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating a data generator for training as it is more economical a=in terms of space utility\n",
    "train_gen = get_batches(train_dir, batch_size=32)\n",
    "# Loading the data for using whole data set to perform validation as well\n",
    "train_img = get_data(train_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 3, 227, 227)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(trn_classes,trn_labels, filenames, test_filenames) = get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okon/anaconda2/envs/newtf/lib/python2.7/site-packages/keras/layers/core.py:630: UserWarning: `output_shape` argument not specified for layer mean_subtraction and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 227, 227)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "alexnet.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (11, 11), strides=(4, 4), activation=\"relu\", name=\"conv_1\")`\n",
      "  name='conv_1')(mean_subtraction)\n",
      "alexnet.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\", name=\"conv_2_1\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_2\")\n",
      "alexnet.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=\"relu\", name=\"conv_2_2\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_2\")\n",
      "alexnet.py:38: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_2\")\n",
      "/home/okon/anaconda2/envs/newtf/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "alexnet.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
      "  conv_3 = Convolution2D(384,3,3,activation='relu',name='conv_3')(conv_3)\n",
      "alexnet.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"conv_4_1\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_4\")\n",
      "alexnet.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"conv_4_2\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_4\")\n",
      "alexnet.py:49: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_4\")\n",
      "alexnet.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv_5_1\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_5\")\n",
      "alexnet.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv_5_2\")`\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_5\")\n",
      "alexnet.py:55: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_5\")\n"
     ]
    }
   ],
   "source": [
    "# Initializing Alexnet model\n",
    "# import gc\n",
    "# gc.collect()\n",
    "inp = Input(shape=(3, 227, 227))\n",
    "weights_path = './weights/alexnet_weights.h5'\n",
    "alexnet = AlexNet_base(input_tensor=inp, weights_path=weights_path)\n",
    "\n",
    "x = Dropout(0.4)(alexnet.get_output_at(-1))\n",
    "x = Dense(10, activation='softmax', name='output')(x)\n",
    "sm_model = Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm_model.compile(optimizer=keras.optimizers.Adam(lr=0.0001, decay=0.005), loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 227, 227)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mean_subtraction (Lambda)       (None, 3, 227, 227)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 55, 55)   34944       mean_subtraction[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 96, 27, 27)   0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convpool_1 (Lambda)             (None, 96, 27, 27)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 96, 31, 31)   0           convpool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 48, 31, 31)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 48, 31, 31)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_1 (Conv2D)               (None, 128, 27, 27)  153728      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 128, 27, 27)  153728      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Merge)                  (None, 256, 27, 27)  0           conv_2_1[0][0]                   \n",
      "                                                                 conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 13, 13)  0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 256, 13, 13)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 256, 15, 15)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 384, 13, 13)  885120      zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 384, 15, 15)  0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 192, 15, 15)  0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 192, 15, 15)  0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_1 (Conv2D)               (None, 192, 13, 13)  331968      lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 192, 13, 13)  331968      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Merge)                  (None, 384, 13, 13)  0           conv_4_1[0][0]                   \n",
      "                                                                 conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 384, 15, 15)  0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 192, 15, 15)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 192, 15, 15)  0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 128, 13, 13)  221312      lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_2 (Conv2D)               (None, 128, 13, 13)  221312      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Merge)                  (None, 256, 13, 13)  0           conv_5_1[0][0]                   \n",
      "                                                                 conv_5_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convpool_5 (MaxPooling2D)       (None, 256, 6, 6)    0           conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9216)         0           convpool_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         37752832    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           40970       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 40,127,882\n",
      "Trainable params: 40,127,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks(res_path):\n",
    "    es = EarlyStopping(patience=4, verbose=1, monitor='val_loss')\n",
    "    rlrp = ReduceLROnPlateau(factor=0.5, patience=2, verbose=1, monitor='val_loss')\n",
    "    ckp = ModelCheckpoint(model_path+'alexnet_trained_model.hdf5', monitor='val_loss', mode = 'min', save_best_only=True, verbose=1)\n",
    "    return es, rlrp, ckp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ver = 'benchmark_V6'\n",
    "model_path = 'data/models/'+ver+'/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22424/22424 [==============================] - 1281s 57ms/step - loss: 0.2840 - acc: 0.9130\n",
      "Epoch 2/15\n",
      "22424/22424 [==============================] - 1316s 59ms/step - loss: 0.0216 - acc: 0.9947\n",
      "Epoch 3/15\n",
      "22424/22424 [==============================] - 1533s 68ms/step - loss: 0.0081 - acc: 0.9982\n",
      "Epoch 4/15\n",
      "22424/22424 [==============================] - 1527s 68ms/step - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 5/15\n",
      "22424/22424 [==============================] - 1532s 68ms/step - loss: 0.0021 - acc: 0.9999\n",
      "Epoch 6/15\n",
      "22424/22424 [==============================] - 1526s 68ms/step - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 7/15\n",
      "22424/22424 [==============================] - 1524s 68ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 8/15\n",
      "22424/22424 [==============================] - 1521s 68ms/step - loss: 0.0012 - acc: 0.9999\n",
      "Epoch 9/15\n",
      "22424/22424 [==============================] - 1521s 68ms/step - loss: 7.4418e-04 - acc: 1.0000\n",
      "Epoch 10/15\n",
      "22424/22424 [==============================] - 1519s 68ms/step - loss: 6.2795e-04 - acc: 1.0000\n",
      "Epoch 11/15\n",
      "22424/22424 [==============================] - 1520s 68ms/step - loss: 8.7856e-04 - acc: 0.9998\n",
      "Epoch 12/15\n",
      "22424/22424 [==============================] - 1527s 68ms/step - loss: 6.6526e-04 - acc: 1.0000\n",
      "Epoch 13/15\n",
      "22424/22424 [==============================] - 1532s 68ms/step - loss: 4.4659e-04 - acc: 1.0000\n",
      "Epoch 14/15\n",
      "22424/22424 [==============================] - 1539s 69ms/step - loss: 3.5110e-04 - acc: 1.0000\n",
      "Epoch 15/15\n",
      "22424/22424 [==============================] - 1537s 69ms/step - loss: 3.2520e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56c003f910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For trainig look at the accuracy and run for 3-3 epochs for better convergence\n",
    "es, rlrp, ckp = get_callbacks(model_path)\n",
    "sm_model.fit(train_img, trn_labels ,batch_size=64, epochs=15, verbose=1)\n",
    "             #callbacks=[es, rlrp, ckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm_model.save_weights(model_path+'alexnet_trained_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22424/22424 [==============================] - 477s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00011943863339129874, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_model.load_weights(model_path+'alexnet_trained_model.hdf5')\n",
    "sm_model.evaluate(train_img, trn_labels, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "1246/1246 [==============================] - 3888s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Test generator(put the test folder in test_all folder)\n",
    "test_imgs = get_batches(test_dir, batch_size=64)\n",
    "pred_res = sm_model.predict_generator(test_imgs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(train_gen.class_indices, key=train_gen.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)\n",
    "def do_clip(arr, mx): return np.clip(arr, 0, 1)\n",
    "\n",
    "#sub = do_clip(pred_res,0.93)\n",
    "sub = do_clip(pred_res,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.072103</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.042754</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.878685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img        c0        c1        c2        c3        c4        c5  \\\n",
       "0       img_1.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "1      img_10.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "2     img_100.jpg  0.072103  0.007778  0.007778  0.042754  0.007778  0.007778   \n",
       "3    img_1000.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "4  img_100000.jpg  0.007778  0.007778  0.007778  0.011136  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.007778  0.007778  \n",
       "2  0.007778  0.007778  0.007778  0.878685  \n",
       "3  0.007778  0.007778  0.930000  0.007778  \n",
       "4  0.007778  0.007778  0.019168  0.930000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(train_gen.class_indices, key=train_gen.class_indices.get)\n",
    "submission = pd.DataFrame(sub, columns=classes)\n",
    "submission.insert(0, 'img', [a[5:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(model_path+'softmax_sub'+ver+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/models/benchmark_V6/subbenchmark_V6.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path+'sub'+ver+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22424/22424 [==============================] - 480s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Input features to resnet\n",
    "alexnet_feats = alexnet.predict(train_img, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=SVC(probability=True, verbose=True, kernel='rbf')\n",
    "clf.fit(alexnet_feats, trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1246 [==============================] - 3354s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79726, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Input features to Resnet\n",
    "pred_test_res = alexnet.predict_generator(test_imgs, verbose=1)\n",
    "pred = clf.predict_proba(pred_test_res)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.030901</td>\n",
       "      <td>0.011270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.134142</td>\n",
       "      <td>0.021183</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.096222</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.724275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.094278</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.054774</td>\n",
       "      <td>0.795840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img        c0        c1        c2        c3        c4        c5  \\\n",
       "0       img_1.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "1      img_10.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "2     img_100.jpg  0.134142  0.021183  0.007778  0.096222  0.007822  0.007778   \n",
       "3    img_1000.jpg  0.007778  0.010063  0.007778  0.007778  0.007778  0.007778   \n",
       "4  img_100000.jpg  0.009578  0.007778  0.007778  0.094278  0.023633  0.020791   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.030901  0.011270  \n",
       "2  0.007778  0.007778  0.010538  0.724275  \n",
       "3  0.007778  0.007778  0.930000  0.007778  \n",
       "4  0.007778  0.007778  0.054774  0.795840  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = do_clip(pred,0.93)\n",
    "classes = sorted(train_gen.class_indices, key=train_gen.class_indices.get)\n",
    "submission = pd.DataFrame(sub, columns=classes)\n",
    "submission.insert(0, 'img', [a[5:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(model_path+'svm_sub'+ver+'svm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
